{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_type_list = ['User_ID', 'Gender', 'Age', 'Occupation', 'Star_Sign', 'Date', 'Text']\n",
    "top_word_list = ['anyways', 'cuz', 'digest', 'diva', 'evermean', 'fox', 'gonna', 'greg', 'haha', 'jayel',\n",
    "                 'kinda', 'levengals', 'literacy', 'lol', 'melissa', 'nan', 'nat', 'postcount', 'ppl', 'rick',\n",
    "                 'school', 'shep', 'sherry', 'spanners', 'teri', 'u', 'ur', 'urllink', 'wanna', 'work']\n",
    "top_type_list = ['Instance_ID'] + top_word_list + ['Class']\n",
    "raw_file_dict = {'train': 'train_raw.csv', 'dev': 'dev_raw.csv', 'test': 'test_raw.csv'}\n",
    "top_file_dict = {'train': 'train_top10.csv', 'dev': 'dev_top10.csv', 'test': 'test_top10.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_data(file_name):\n",
    "    if 'raw' in file_name:\n",
    "        input_data = pd.read_csv(file_name, names=raw_type_list)\n",
    "    else:\n",
    "        input_data = pd.read_csv(file_name, names=top_type_list)\n",
    "#     input_data = input_data[input_data['Class'] != '?']\n",
    "    # df = pd.DataFrame({'Age': input_data['Age'], 'Text': input_data['Text']})\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_class(raw):\n",
    "    if raw == '14-16':\n",
    "        return 0\n",
    "    elif raw == '24-26':\n",
    "        return 1\n",
    "    elif raw == '34-36':\n",
    "        return 2\n",
    "    elif raw == '44-46':\n",
    "        return 3\n",
    "\n",
    "def convert_dict(file_name):\n",
    "    new_X = []\n",
    "    f = open(file_name, 'r')\n",
    "    for line in f:\n",
    "        atts = line[:-1].split(\",\")\n",
    "        this = {}\n",
    "        count = 1\n",
    "        for type in top_word_list:\n",
    "            this[type] = int(atts[count])\n",
    "            count += 1\n",
    "        new_X.append(this)\n",
    "    f.close()\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = top_file_dict['train']\n",
    "data_train = read_raw_data(file_name)\n",
    "\n",
    "file_name = top_file_dict['dev']\n",
    "data_test = read_raw_data(file_name)\n",
    "\n",
    "X_train = data_train.iloc[:, 1:-1]\n",
    "y_train = data_train.iloc[:, -1]\n",
    "\n",
    "X_test = data_test.iloc[:, 1:-1]\n",
    "y_test = data_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-R: 0.3815847524927204\n"
     ]
    }
   ],
   "source": [
    "# Zero R - 38%\n",
    "from sklearn.dummy import DummyClassifier\n",
    "zero_r = DummyClassifier(strategy='most_frequent')\n",
    "zero_r.fit(X_train, y_train)\n",
    "print(\"Zero-R:\", accuracy_score(zero_r.predict(X_test), y_test))\n",
    "# cross_val_score(zero_r, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.4329612635665755\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree - 43%\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(max_depth=None)\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"Decision Tree:\", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN - %\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "# neigh.fit(X_train, y_train)\n",
    "# print(\"KNN:\", neigh.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC - %\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"LinearSVC:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC - \n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"SVC:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: 0.42634342186534896\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - 42%\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distributions of top 30 words\n",
    "word_dict = {'anyways': {'14-16': 6268, '24-26': 2887, '34-36': 185, '44-46': 14},\n",
    "             'cuz': {'14-16': 7991, '24-26': 1945, '34-36': 377, '44-46': 9},\n",
    "             'digest': {'14-16': 37, '24-26': 106, '34-36': 1147, '44-46': 4},\n",
    "             'diva': {'14-16': 33, '24-26': 172, '34-36': 631, '44-46': 0},\n",
    "             'evermean': {'14-16': 0, '24-26': 0, '34-36': 259, '44-46': 0},\n",
    "             'fox': {'14-16': 303, '24-26': 684, '34-36': 171, '44-46': 783},\n",
    "             'gonna': {'14-16': 15897, '24-26': 6463, '34-36': 644, '44-46': 237},\n",
    "             'greg': {'14-16': 241, '24-26': 691, '34-36': 159, '44-46': 528},\n",
    "             'haha': {'14-16': 12247, '24-26': 1721, '34-36': 75, '44-46': 5},\n",
    "             'jayel': {'14-16': 0, '24-26': 0, '34-36': 0, '44-46': 161},\n",
    "             'kinda': {'14-16': 8676, '24-26': 4271, '34-36': 368, '44-46': 128},\n",
    "             'levengals': {'14-16': 0, '24-26': 0, '34-36': 0, '44-46': 163},\n",
    "             'literacy': {'14-16': 12, '24-26': 112, '34-36': 535, '44-46': 7},\n",
    "             'lol': {'14-16': 17475, '24-26': 2195, '34-36': 542, '44-46': 873},\n",
    "             'melissa': {'14-16': 371, '24-26': 356, '34-36': 24, '44-46': 276},\n",
    "             'nan': {'14-16': 108, '24-26': 115, '34-36': 10, '44-46': 159},\n",
    "             'nat': {'14-16': 264, '24-26': 97, '34-36': 2, '44-46': 225},\n",
    "             'postcount': {'14-16': 0, '24-26': 356, '34-36': 389, '44-46': 0},\n",
    "             'ppl': {'14-16': 5155, '24-26': 791, '34-36': 54, '44-46': 0},\n",
    "             'rick': {'14-16': 164, '24-26': 513, '34-36': 229, '44-46': 945},\n",
    "             'school': {'14-16': 21845, '24-26': 13784, '34-36': 3026, '44-46': 667},\n",
    "             'shep': {'14-16': 3, '24-26': 0, '34-36': 2, '44-46': 310},\n",
    "             'sherry': {'14-16': 17, '24-26': 54, '34-36': 16, '44-46': 195},\n",
    "             'spanners': {'14-16': 0, '24-26': 1, '34-36': 104, '44-46': 0},\n",
    "             'teri': {'14-16': 14, '24-26': 14, '34-36': 3, '44-46': 108},\n",
    "             'u': {'14-16': 24316, '24-26': 5753, '34-36': 329, '44-46': 61},\n",
    "             'ur': {'14-16': 4854, '24-26': 873, '34-36': 21, '44-46': 1},\n",
    "             'urllink': {'14-16': 29240, '24-26': 93701, '34-36': 24976, '44-46': 4465},\n",
    "             'wanna': {'14-16': 8377, '24-26': 2986, '34-36': 268, '44-46': 54},\n",
    "             'work': {'14-16': 13242, '24-26': 40902, '34-36': 8489, '44-46': 1807}}\n",
    "\n",
    "# for k, v in word_dict.items():\n",
    "#     print(v)\n",
    "#     plt.bar(range(len(v)), list(v.values()), align='center')\n",
    "#     plt.xticks(range(len(v)), list(v.keys()))\n",
    "#     plt.title(k)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4306450189711462"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial NB - 43%\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"MultinomialNB:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41601958881143564"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian NB - 41%\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"GaussianNB:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
