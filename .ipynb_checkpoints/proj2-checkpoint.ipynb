{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER LIST\n",
    "\n",
    "raw_type_list = ['User_ID', 'Gender', 'Age', 'Occupation', 'Star_Sign', 'Date', 'Text']\n",
    "top_word_list = ['anyways', 'cuz', 'digest', 'diva', 'evermean', 'fox', 'gonna', 'greg', 'haha', 'jayel',\n",
    "                 'kinda', 'levengals', 'literacy', 'lol', 'melissa', 'nan', 'nat', 'postcount', 'ppl', 'rick',\n",
    "                 'school', 'shep', 'sherry', 'spanners', 'teri', 'u', 'ur', 'urllink', 'wanna', 'work']\n",
    "top_type_list = ['Instance_ID'] + top_word_list + ['Class']\n",
    "raw_file_dict = {'train': 'train_raw.csv', 'dev': 'dev_raw.csv', 'test': 'test_raw.csv'}\n",
    "top_file_dict = {'train': 'train_top10.csv', 'dev': 'dev_top10.csv', 'test': 'test_top10.csv'}\n",
    "\n",
    "age_distribution = {'14-16': 98454, '24-26': 141104, '34-36': 30347, '44-46': 6510}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTION\n",
    "\n",
    "def read_data(file_name):\n",
    "    if 'raw' in file_name:\n",
    "        input_data = pd.read_csv(file_name, names=raw_type_list)\n",
    "    else:\n",
    "        input_data = pd.read_csv(file_name, names=top_type_list)\n",
    "    return input_data\n",
    "\n",
    "def read_id(file_name):\n",
    "    f = open(file_name)\n",
    "    lst = []\n",
    "\n",
    "    for line in f.readlines():\n",
    "        row = line.rstrip().split(',')\n",
    "        lst.append(row[0])\n",
    "    f.close()\n",
    "    return lst\n",
    "\n",
    "def preprocess(id_lst, X_lst, y_lst, num):\n",
    "    X_dict = {x: [0 for i in range(num)] for x in id_lst}\n",
    "    y_dict = {}\n",
    "    for i in range(len(id_lst)):\n",
    "        X_dict[id_lst[i]] += X_lst[i]\n",
    "        y_dict[id_lst[i]] = y_lst[i]\n",
    "\n",
    "    id_set = [k for k in X_dict.keys()]\n",
    "    X = [v.tolist() for v in X_dict.values()]\n",
    "    y = [v for v in y_dict.values()]\n",
    "\n",
    "    return id_set, X, y\n",
    "\n",
    "def convert_back(y_pred, id_lst, id_set):\n",
    "    pred_dict = {}\n",
    "\n",
    "    for i in range(len(id_set)):\n",
    "        pred_dict[id_set[i]] = y_pred[i]\n",
    "\n",
    "    y_new_pred = []\n",
    "    for i in range(len(id_lst)):\n",
    "        y_new_pred.append(pred_dict[id_lst[i]])\n",
    "\n",
    "    return y_new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data - get feature names\n",
    "train_raw = raw_file_dict['train']\n",
    "train_text = read_data(train_raw).iloc[:, -1]\n",
    "train_text = train_text.replace('[^a-zA-Z ]', '', regex=True)\n",
    "\n",
    "train_CV = CountVectorizer(lowercase=True)\n",
    "train_table = train_CV.fit_transform(train_text)\n",
    "train_feature_names = train_CV.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data - read given 2 datasets\n",
    "train_top = top_file_dict['train']\n",
    "train_id = read_id(train_raw)\n",
    "train_data = read_data(train_top).as_matrix()\n",
    "y_train = train_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data - select 500 best feature names\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=1000)\n",
    "selector.fit_transform(train_table, y=y_train)\n",
    "\n",
    "mask = selector.get_support()\n",
    "train_features = []\n",
    "train_features_index = []\n",
    "\n",
    "for bool, index in zip(mask, range(len(train_feature_names))):\n",
    "    if bool:\n",
    "        train_features.append(train_feature_names[index])\n",
    "        train_features_index.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n"
     ]
    }
   ],
   "source": [
    "# convert into X_train format\n",
    "train_word_data = []\n",
    "for i in range(len(train_text)):\n",
    "    if i % 10000 == 0: print(i)\n",
    "    train_ins_data = train_table[i].toarray()[0]\n",
    "    train_ins_word = [train_ins_data[j] for j in train_features_index]\n",
    "    train_word_data.append(train_ins_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276415, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train data to numpy array\n",
    "train_data_np = np.array(train_word_data)\n",
    "train_data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train numpy array to pandas DataFrame\n",
    "train_data_df = pd.DataFrame(train_data_np, columns=train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev data\n",
    "dev_top = top_file_dict['dev']\n",
    "dev_raw = raw_file_dict['dev']\n",
    "dev_id = read_id(dev_raw)\n",
    "dev_data = read_data(dev_top).as_matrix()\n",
    "y_dev = dev_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev data - get feature names\n",
    "dev_text = read_data(dev_raw).iloc[:,-1]\n",
    "dev_text = dev_text.replace('[^a-zA-Z ]', '', regex=True)\n",
    "\n",
    "dev_CV = CountVectorizer(lowercase=True)\n",
    "dev_table = dev_CV.fit_transform(dev_text)\n",
    "dev_feature_names = dev_CV.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev data - select same k features\n",
    "dev_features = []\n",
    "dev_features_index = []\n",
    "for i in range(len(dev_feature_names)):\n",
    "    if dev_feature_names[i] in train_features:\n",
    "        dev_features_index.append(i)\n",
    "        dev_features.append(dev_feature_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "# convert into X_dev format\n",
    "dev_word_data = []\n",
    "for i in range(len(dev_text)):\n",
    "    if i % 10000 == 0: print(i)\n",
    "    dev_ins_data = dev_table[i].toarray()[0]\n",
    "    dev_ins_word = [dev_ins_data[j] for j in dev_features_index]\n",
    "    dev_word_data.append(dev_ins_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45332, 912)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_dev data into numpy array\n",
    "dev_data_np = np.array(dev_word_data)\n",
    "dev_data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_dev numpy array into pandas DataFrame\n",
    "dev_data_df = pd.DataFrame(dev_data_np, columns=dev_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the non-existing features with all zeros column\n",
    "dev_missed_features = [x for x in train_features if x not in dev_features]\n",
    "for miss in dev_missed_features:\n",
    "    dev_data_df[miss] = [0 for i in range(len(dev_data_np))]\n",
    "dev_data_df = dev_data_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = train_data_df.as_matrix()\n",
    "X_dev_ = dev_data_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_top = top_file_dict['test']\n",
    "test_raw = raw_file_dict['test']\n",
    "test_id = read_id(test_raw)\n",
    "test_data = read_data(test_top).as_matrix()\n",
    "y_test = test_data[:, -1]\n",
    "test_index = test_data[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data - get feature names\n",
    "test_text = read_data(test_raw).iloc[:,-1]\n",
    "test_text = test_text.replace('[^a-zA-Z ]', '', regex=True)\n",
    "\n",
    "test_CV = CountVectorizer(lowercase=True)\n",
    "test_table = test_CV.fit_transform(test_text)\n",
    "test_feature_names = test_CV.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data - select same k features\n",
    "test_features = []\n",
    "test_features_index = []\n",
    "for i in range(len(test_feature_names)):\n",
    "    if test_feature_names[i] in train_features:\n",
    "        test_features_index.append(i)\n",
    "        test_features.append(test_feature_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "# convert into X_test format\n",
    "test_word_data = []\n",
    "for i in range(len(test_text)):\n",
    "    if i % 10000 ==0:\n",
    "        print(i)\n",
    "    test_ins_data = test_table[i].toarray()[0]\n",
    "    test_ins_word = [test_ins_data[j] for j in test_features_index]\n",
    "    test_word_data.append(test_ins_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43014, 909)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test data into numpy array\n",
    "test_data_np = np.array(test_word_data)\n",
    "test_data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test numpy array into pandas DataFrame\n",
    "test_data_df = pd.DataFrame(test_data_np, columns=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the non-existing features with all zeros column\n",
    "test_missed_features = [x for x in train_features if x not in test_features]\n",
    "for miss in test_missed_features:\n",
    "    test_data_df[miss] = [0 for i in range(len(test_data_np))]\n",
    "test_data_df = test_data_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = test_data_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING FINISHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_set, X_new_train, y_new_train = preprocess(train_id, X_train_, y_train, 1000)\n",
    "dev_id_set, X_new_dev, y_new_dev = preprocess(dev_id, X_dev_, y_dev, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id_set, X_new_test, y_new_test = preprocess(test_id, X_test_, y_test, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (Dev): 0.49896320480014117\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree - Dev - 53.51%\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=None)\n",
    "dt.fit(X_new_train, y_new_train)\n",
    "y_dev_pred = dt.predict(X_new_dev)\n",
    "y_new_dev_pred = convert_back(y_dev_pred, dev_id, dev_id_set)\n",
    "print(\"Decision Tree (Dev):\", accuracy_score(y_dev, y_new_dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Dev): 0.6177093443924822\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - Test - 61.46%\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_new_train, y_new_train)\n",
    "y_dev_pred = clf.predict(X_new_dev)\n",
    "y_new_dev_pred = convert_back(y_dev_pred, dev_id, dev_id_set)\n",
    "print(\"Logistic Regression (Dev):\", accuracy_score(y_dev, y_new_dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction for test data\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_new_train, y_new_train)\n",
    "y_test_pred = clf.predict(X_new_test)\n",
    "y_new_test_pred = convert_back(y_test_pred, test_id, test_id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output csv file - use logistic regression\n",
    "lst = test_data[:, 0].tolist()\n",
    "df = pd.DataFrame()\n",
    "df['Id'] = lst\n",
    "df['Prediction'] = y_new_test_pred\n",
    "df.to_csv('out-1000.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest - Dev - 57.83%\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "clf.fit(X_new_train, y_new_train)\n",
    "y_dev_pred = clf.predict(X_new_dev)\n",
    "y_new_dev_pred = convert_back(y_dev_pred, dev_id, dev_id_set)\n",
    "print(\"Random Forest (Dev):\", accuracy_score(y_dev, y_new_dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest + Grid Search CV - Dev - 54.63%\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "CV_rfc.fit(X_new_train, y_new_train)\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc1 = RandomForestClassifier(random_state=0, max_features='auto', n_estimators=700, max_depth=None)\n",
    "rfc1.fit(X_new_train, y_new_train)\n",
    "y_dev_pred = clf.predict(X_new_dev)\n",
    "y_new_dev_pred = convert_back(y_dev_pred, dev_id, dev_id_set)\n",
    "print(\"Grid Search (Dev):\", accuracy_score(y_dev, y_new_dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find instances with all zeros\n",
    "count = 0\n",
    "for i in range(len(X_new_train)):\n",
    "    allzero = True\n",
    "#     print(i, X_new_train[i])\n",
    "    for j in X_new_train[i]:\n",
    "        if j != 0:\n",
    "            allzero = False\n",
    "    if allzero:\n",
    "        count += 1\n",
    "#         print(i, X_new_train[i])\n",
    "print(count / len(X_new_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC - Dev - 38.56%\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(X_new_train, y_new_train)\n",
    "y_dev_pred = clf.predict(X_new_dev)\n",
    "y_new_dev_pred = convert_back(y_dev_pred, dev_id, dev_id_set)\n",
    "print(\"Linear SVC (Dev):\", accuracy_score(y_dev, y_new_dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "file_name = top_file_dict['train']\n",
    "data_train = read_data(file_name)\n",
    "X_train = data_train.iloc[:, 1:-1]\n",
    "y_train = data_train.iloc[:, -1]\n",
    "\n",
    "file_name = top_file_dict['dev']\n",
    "data_test = read_data(file_name)\n",
    "X_test = data_test.iloc[:, 1:-1]\n",
    "y_test = data_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero R - 38% / 51%\n",
    "from sklearn.dummy import DummyClassifier\n",
    "zero_r = DummyClassifier(strategy='most_frequent')\n",
    "zero_r.fit(X_train, y_train)\n",
    "print(\"Zero-R:\", accuracy_score(zero_r.predict(X_dev), y_dev))\n",
    "# cross_val_score(zero_r, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree - 43.296% / 58%\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(max_depth=25)\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"Decision Tree:\", dt.score(X_dev, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest - 43.512% <21>\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=21, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Random Forest:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Tree Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf = ExtraTreesClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Extra Trees:\", clf.score(X_test, y_test))\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new_train = model.transform(X_train)\n",
    "X_new_test = model.transform(X_test)\n",
    "clf.fit(X_new_train, y_train)\n",
    "y_pred = clf.predict(X_new_test)\n",
    "print(\"Extra Trees:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Classifier - 0.4352775081620048<25,2>\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(25, 2), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"MLP Classifier:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for test data\n",
    "\n",
    "file_name = top_file_dict['test']\n",
    "data_train = read_raw_data(file_name)\n",
    "index = data_train.iloc[:, 0]\n",
    "X_pred = data_train.iloc[:, 1:-1]\n",
    "y_pred = clf.predict(X_pred)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Id'] = index\n",
    "df['Prediction'] = y_pred\n",
    "df.to_csv('out.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN - %\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "print(\"KNN:\", neigh.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC - %\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"LinearSVC:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC - %\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"SVC:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression - 42.63% / 57%\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Logistic:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial NB - 43% / 58%\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"MultinomialNB:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian NB - 41% / 56%\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"GaussianNB:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_digit(raw):\n",
    "    if raw in range(14, 17): return 0\n",
    "    elif raw in range(24, 27): return 1\n",
    "    elif raw in range(34, 37): return 2\n",
    "    elif raw in range(44, 47): return 3\n",
    "\n",
    "data = pd.read_csv(\"train_raw.csv\", names=raw_type_list)\n",
    "X = []\n",
    "y = []\n",
    "for index, text in data.iterrows():\n",
    "    if index > 1000:\n",
    "        break\n",
    "    nopunc = re.sub(r'[^a-zA-Z0-9 ]', '', text['Text'])\n",
    "    X.append(len(set(nopunc.split())))\n",
    "    y.append(convert_digit(text['Age']))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import lemma\n",
    "\n",
    "print(lemma('working'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Build a classification task using 3 informative features\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "clf = LinearSVC(C=1.0)\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=clf, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy')\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_raw_data('train_raw.csv')\n",
    "\n",
    "X = []\n",
    "X_length = []\n",
    "for index, text in data.iterrows():\n",
    "    user_id = text['User_ID']\n",
    "#     print(user_id)\n",
    "    nopunc = re.sub(r'[^a-zA-Z0-9 ]', '', text['Text'])\n",
    "    X.append(nopunc.split())\n",
    "    X_length.append(nopunc.split())\n",
    "\n",
    "# print(sum(X_length)/len(X_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Distribution in train data\n",
    "count = {}\n",
    "for k in ['14-16','24-26','34-36','44-46']:\n",
    "    count[k]=0\n",
    "total = 0\n",
    "for k in y_train:\n",
    "    count[k] += 1\n",
    "for k in ['14-16','24-26','34-36','44-46']:\n",
    "    total += count[k]\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {word: {'14-16': 0, '24-26': 0, '34-36': 0, '44-46': 0} for word in top_word_list}\n",
    "    \n",
    "for word in top_word_list:\n",
    "    for index, row in data_train.iterrows():\n",
    "        if row[word] > 0:\n",
    "            dic[word][y_train[index]] += 1\n",
    "\n",
    "for word in top_word_list:\n",
    "    _sum = 0\n",
    "    for j in ['14-16','24-26','34-36','44-46']:\n",
    "        dic[word][j] = total*dic[word][j]/count[j]\n",
    "        _sum += dic[i][j]\n",
    "    for j in ['14-16','24-26','34-36','44-46']:\n",
    "        dic[word][j] = dic[word][j] / _sum\n",
    "\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distributions of top 30 words\n",
    "\n",
    "word_dict = {word: {'14-16': 0, '24-26': 0, '34-36': 0, '44-46': 0} for word in top_word_list}\n",
    "for index, row in data_train.iterrows():\n",
    "    for word in top_word_list:\n",
    "        if row[word] != 0:\n",
    "            word_dict[word][row['Class']] += 1\n",
    "            \n",
    "word_dict = {'anyways': {'14-16': 4944, '24-26': 2441, '34-36': 168, '44-46': 13},\n",
    "             'cuz': {'14-16': 4819, '24-26': 1381, '34-36': 233, '44-46': 8},\n",
    "             'digest': {'14-16': 36, '24-26': 102, '34-36': 369, '44-46': 4},\n",
    "             'diva': {'14-16': 31, '24-26': 125, '34-36': 453, '44-46': 0},\n",
    "             'evermean': {'14-16': 0, '24-26': 0, '34-36': 105, '44-46': 0},\n",
    "             'fox': {'14-16': 187, '24-26': 508, '34-36': 111, '44-46': 417},\n",
    "             'gonna': {'14-16': 10597, '24-26': 4874, '34-36': 547, '44-46': 207},\n",
    "             'greg': {'14-16': 151, '24-26': 464, '34-36': 112, '44-46': 317},\n",
    "             'haha': {'14-16': 6416, '24-26': 1364, '34-36': 70, '44-46': 5},\n",
    "             'jayel': {'14-16': 0, '24-26': 0, '34-36': 0, '44-46': 157},\n",
    "             'kinda': {'14-16': 6598, '24-26': 3635, '34-36': 336, '44-46': 110},\n",
    "             'levengals': {'14-16': 0, '24-26': 0, '34-36': 0, '44-46': 137},\n",
    "             'literacy': {'14-16': 11, '24-26': 64, '34-36': 171, '44-46': 6},\n",
    "             'lol': {'14-16': 8422, '24-26': 1557, '34-36': 408, '44-46': 444},\n",
    "             'melissa': {'14-16': 250, '24-26': 275, '34-36': 21, '44-46': 225},\n",
    "             'nan': {'14-16': 88, '24-26': 56, '34-36': 6, '44-46': 145},\n",
    "             'nat': {'14-16': 195, '24-26': 78, '34-36': 2, '44-46': 204},\n",
    "             'postcount': {'14-16': 0, '24-26': 356, '34-36': 389, '44-46': 0},\n",
    "             'ppl': {'14-16': 3343, '24-26': 531, '34-36': 36, '44-46': 0},\n",
    "             'rick': {'14-16': 125, '24-26': 350, '34-36': 148, '44-46': 519},\n",
    "             'school': {'14-16': 13610, '24-26': 9365, '34-36': 1853, '44-46': 414},\n",
    "             'shep': {'14-16': 3, '24-26': 0, '34-36': 2, '44-46': 190},\n",
    "             'sherry': {'14-16': 11, '24-26': 48, '34-36': 13, '44-46': 180},\n",
    "             'spanners': {'14-16': 0, '24-26': 1, '34-36': 99, '44-46': 0},\n",
    "             'teri': {'14-16': 6, '24-26': 12, '34-36': 3, '44-46': 102},\n",
    "             'u': {'14-16': 9139, '24-26': 2547, '34-36': 142, '44-46': 28},\n",
    "             'ur': {'14-16': 2909, '24-26': 537, '34-36': 14, '44-46': 1},\n",
    "             'urllink': {'14-16': 14835, '24-26': 46685, '34-36': 13404, '44-46': 2139},\n",
    "             'wanna': {'14-16': 5750, '24-26': 2196, '34-36': 210, '44-46': 46},\n",
    "             'work': {'14-16': 9719, '24-26': 26484, '34-36': 5452, '44-46': 1211}}\n",
    "\n",
    "Plot the bar graph\n",
    "for k, v in word_dict.items():\n",
    "    print(v)\n",
    "    plt.bar(range(len(v)), list(v.values()), align='center')\n",
    "    plt.xticks(range(len(v)), list(v.keys()))\n",
    "    plt.title(k)\n",
    "    plt.show()\n",
    "    \n",
    "age_dict = {'14-16': {}, '24-26': {}, '34-36': {}, '44-46': {}}\n",
    "new_age_dict = {'14-16': {}, '24-26': {}, '34-36': {}, '44-46': {}}\n",
    "\n",
    "for k, v in word_dict.items():\n",
    "    for ks, vs in age_dict.items():\n",
    "        age_dict[ks][k] = word_dict[k][ks]\n",
    "\n",
    "for k, v in age_dict.items():\n",
    "    new_age_dict[k] = list(reversed(sorted(v.items(), key=operator.itemgetter(1))))\n",
    "\n",
    "# Top 10 feature distributions (normalised)\n",
    "'14-16': [('ppl', 0.8727789149847253), ('ur', 0.8698564164613034), ('haha', 0.8364584267053635), \n",
    "          ('u', 0.7744724558628764), ('cuz', 0.7236296537282069), ('anyways', 0.6691182379567854), \n",
    "          ('wanna', 0.6640323036842943), ('gonna', 0.5605997007713579), ('kinda', 0.5550158468463889), \n",
    "          ('lol', 0.47997133335565567)]\n",
    "'24-26': [('work', 0.287832939550357), ('urllink', 0.2643041783638263), ('anyways', 0.230508118020287), \n",
    "          ('kinda', 0.2133494499066458), ('school', 0.20157074400041788), ('gonna', 0.17990759264086534), \n",
    "          ('wanna', 0.17694884758888418), ('postcount', 0.16445487302236883), ('u', 0.15060184225208706), \n",
    "          ('cuz', 0.14469287565639952)]\n",
    "'34-36': [('evermean', 1.0), ('spanners', 0.9978323018665548), ('diva', 0.9255497682681122), \n",
    "          ('digest', 0.8771516331479886), ('postcount', 0.8355451269776312), ('literacy', 0.7912104527801802), \n",
    "          ('urllink', 0.35284555075250373), ('work', 0.2755093369403132), ('school', 0.18544652384760632), \n",
    "          ('cuz', 0.11350969350726677)]\n",
    "'44-46': [('levengals', 1.0), ('jayel', 1.0), ('shep', 0.9967087407019541), ('teri', 0.9846137317830624), \n",
    "          ('sherry', 0.9691455026541897), ('nan', 0.937361638189683), ('nat', 0.9234049260898503), \n",
    "          ('rick', 0.9023549096467094), ('fox', 0.8749225398181598), ('melissa', 0.8696562791017377)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTION\n",
    "def convert_class(raw):\n",
    "    if raw == '14-16': return 0\n",
    "    elif raw == '24-26': return 1\n",
    "    elif raw == '34-36': return 2\n",
    "    elif raw == '44-46': return 3\n",
    "\n",
    "def convert_dict(file_name):\n",
    "    X = []\n",
    "    y = []\n",
    "    f = open(file_name, 'r')\n",
    "    for line in f:\n",
    "        atts = line[:-1].split(\",\")\n",
    "        this = {}\n",
    "        count = 1\n",
    "        for type in top_word_list:\n",
    "            this[type] = int(atts[count])\n",
    "            count += 1\n",
    "        if atts[-1] != '?':\n",
    "            X.append(this)\n",
    "            y.append(convert_class(atts[-1]))\n",
    "    f.close()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
